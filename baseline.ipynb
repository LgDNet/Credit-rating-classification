{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aa3fba-31b6-47bf-9a09-7a205aa648c2",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "93a1a3d2-5d74-4dba-9a39-a48646c5d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6c7948fd-60f3-41a5-b430-b805c59bc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ed6d4b3-994e-42d3-84c5-446b2d0e32be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        \"\"\" 생성자 \"\"\"\n",
    "        self._train = pd.read_csv('./data/train_label1.csv')\n",
    "        self._test = pd.read_csv('./data/test.csv')\n",
    "        self._submit = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "        self.result = None\n",
    "    \n",
    "    def preprocessing(self, df):\n",
    "        \"\"\" 전처리기 \"\"\"\n",
    "        #sb\n",
    "        train_object = df['대출목적'].unique()\n",
    "        oject_dict = dict()\n",
    "        for i, v in enumerate(df['대출목적'].unique()):\n",
    "            oject_dict[v] = i\n",
    "        df['대출목적'] = df['대출목적'].apply(lambda x: oject_dict.get(x, '기타'))\n",
    "        # 근로연수 컬럼의 데이터를 문자열로 변환\n",
    "        df['근로기간'] = df['근로기간'].astype(str)\n",
    "        # 숫자만 추출\n",
    "        df['근로기간'] = df['근로기간'].str.extract('(\\d+)').astype(float)\n",
    "        # 'Unknown'은 NaN으로 변환되므로, 이를 -1로 대체\n",
    "        df['근로기간'].fillna(-1, inplace=True)\n",
    "        # '10+'와 같은 표현은 10으로 처리되므로, 이를 10 이상의 값으로 대체\n",
    "        df.loc[df['근로기간'] == 10, '근로기간'] = 11\n",
    "        # '<1 year'와 같은 표현은 NaN으로 처리되므로, 이를 0으로 대체\n",
    "        df.loc[df['근로기간'].isna(), '근로기간'] = 0\n",
    "#label\n",
    "        categoric_col = df.select_dtypes(include='object').columns # 범주형\n",
    "        numeric_col = df.select_dtypes(include='int64').columns # 수치형\n",
    "        \n",
    "        # 범주형 수치형으로 변환\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "        df[categoric_col] = ordinal_encoder.fit_transform(df[categoric_col])\n",
    "        return df\n",
    "        \n",
    "    def scaler(self,df):\n",
    "        # numeric_col = df.select_dtypes(include='int64').columns\n",
    "        df_col = df.columns\n",
    "        if \"대출등급\" in df_col:\n",
    "            df_col = df_col[:-1]\n",
    "        scaler = StandardScaler()\n",
    "        df[df_col] = scaler.fit_transform(df[df_col])\n",
    "        return df\n",
    "        \n",
    "    def train(self, _model):\n",
    "        \"\"\" model 훈련 \"\"\"\n",
    "        # train 전처리\n",
    "        # self._train = self.preprocessing(self._train) \n",
    "        categoric_col = [\"ID\",\"대출등급\"]\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "        self._train[categoric_col] = ordinal_encoder.fit_transform(self._train[categoric_col])\n",
    "        self._train = self.scaler(self._train) #scaler\n",
    "        # train 분리\n",
    "        X = self._train.drop(['대출등급'],axis = 1)\n",
    "        Y = self._train['대출등급']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2 ,random_state=42,stratify=Y)\n",
    "        \n",
    "        # model 훈련 및 평가\n",
    "        _model.fit(x_train,y_train)\n",
    "        y_pred = _model.predict(x_test)\n",
    "        score = f1_score(y_test,y_pred, average=\"macro\")\n",
    "        print(f\"[Score]: {score:.2f}\")\n",
    "        \n",
    "    def test(self):\n",
    "        \"\"\" model 추론 \"\"\"\n",
    "        # test 전처리\n",
    "        self._test = self.preprocessing(self._test) \n",
    "        self._test = self.scaler(self._test) #scaler\n",
    "        \n",
    "        # model 예측\n",
    "        real = self.model.predict(self._test)\n",
    "        self.result = np.where(real == 0, 'A', \n",
    "                      np.where(real == 1, 'B',\n",
    "                      np.where(real == 2, 'C',\n",
    "                      np.where(real == 3, 'D',\n",
    "                      np.where(real == 4, 'E', 'F')))))\n",
    "        \n",
    "    def submit(self):\n",
    "        \"\"\" 제출 \"\"\"\n",
    "        # csv 저장\n",
    "        self._submit['대출등급'] = self.result\n",
    "        self._submit.to_csv(\"submit_2.csv\",index = False)\n",
    "        \n",
    "        # 모델 저장\n",
    "        with open('model.pkl', 'wb') as file:\n",
    "            pickle.dump(self.model, file)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1579a001-7d97-4bdd-9657-9ba46352d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d54aed4a-c906-4f3b-8d7a-f1fa2bd95655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Score]: 0.77\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cbc5bd67-8cd0-4005-a582-5b1d327969ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2af6dfac-0aec-4dd5-a878-8a09db224160",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9e239390-d7d0-4a72-83a3-5888df909551",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=1000, random_state=1)\n",
    "model2 = XGBClassifier()\n",
    "\n",
    "models = [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9d06f738-556a-4a45-9bbc-8c37ae731449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=1), XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)]\n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "940c60fc-ee27-46b0-8f5b-5ac6bd56b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Score]: 0.77\n",
      "[Score]: 0.77\n",
      "[None, None]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(model.train, models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e470c1-bfaa-4caf-9df6-1fb05255ea99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9eae44-44f7-4b54-9046-790974052db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
